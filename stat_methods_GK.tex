\documentclass[12pt]{extarticle}
\usepackage[utf8]{inputenc}
\usepackage{cite}
\usepackage{amsmath}
\usepackage[margin=0.5in]{geometry}
%\usepackage{biblatex}
\usepackage[scientific-notation=true]{siunitx}
\usepackage{xspace}
\newcommand{\ie}{\emph{i.e.}\xspace}
\newcommand{\eg}{\emph{e.g.}\xspace}

\title{Statistical methods for Lerner \& Hepperla \textit{et al.}}
\date{}

\begin{document}

\maketitle

\section*{Description of the data}
We sought to characterize the methylation dynamics of histone H3 at lysine 36 (H3K36) at a majority of yeast genes in three biological conditions: after light activation of LANS-Set2 (writer add:WA), and after dark inactivation of LANS-Set2 with and without the presence of Rph1, a histone deacetylase (writer loss:WL and writer eraser loss:WEL, respectively). H3K36 trimethyl (H3K36me3) levels were measured through ChIP-seq across four timepoints for each condition (0/20/40/60 min for WA and 0/30/60/90 min for WL and WEL) for 5,355 genes. Seq data were collected and quantified from three sample replicates for each condition across the timepoints. We used two different approaches to process the seq data for analysis. First, within each replicate, H3K36me3 levels for a gene and condition were scaled to the proportion of maximum H3K36me3 level observed (for said replicate, gene, and condition), resulting in a common quantile scale across all replicates, genes, and conditions, which we refer to as ``relative H3K36me3 signal" in the text. Second, we took the measurements, previously standardized based on spike-in samples and normalized to adjust for gene length, multiplied them by 1000, and rounded to an integer, resulting in count data (quasi-counts) with a distribution proportional to the starting data. 

\section*{General statistical model}
Though the H3K36me3 data were large and well-balanced--the vast majority of genes having complete measurements of three replicates from each condition across four timepoints--they possess challenging features from a statistical modeling perspective. The statistical model should accommodate the non-normal distribution of the H3K36me3 data, as well as the time course, \ie longitudinal, nature of observations within a replicate. This broad range of features can be flexibly handled using Bayesian inference \cite{Gelman2006, Gelman2013}. 
	
The Stan statistical platform \cite{Carpenter2017} is one such computational tool for fitting complex Bayesian hierarchical models. We used the brms software package \cite{Burkner2017, Burkner2018}, which acts as a wrapper of Stan in the R statistical programming language \cite{RCoreTeam2019}. Let $y_{ijkl}$ be the H3K36me3 measurement for the $i$\textsuperscript{th} replicate sample ($i=1,2,3$) at the $j$\textsuperscript{th} timepoint ($j=0,1,2,3$) for the $k$\textsuperscript{th} gene ($k=1,2,â€¦,5355$) for $l$\textsuperscript{th} condition ($l=1,2,3$). Briefly, we model $y$ with a GLM by defining $E(y)=g^{-1}(\eta)$, where $E(.)$ is the expected value of a random variable, $g^{-1}(.)$ is the inverse link function, and $\eta$ is the linear predictor that relates the outcome to factors of interest.
	
A Bayesian analysis could in principle simultaneously model all genes and conditions, though in practice, such an approach would likely be computationally infeasible, particularly when considering the need for sufficient sampling in order for the parameter estimates to converge. To avoid these challenges, we instead model more manageable subsets of H3K36me3 data. First, we fit a model of H3K36me3 data for a specific gene and condition. Second, to make more direct comparisons between the writer loss and writer eraser loss conditions, we modeled their data jointly within a gene.
	
\section*{Zero-one-inflated beta regression model of H3K36me3 quantiles}
For the H3K36me3 data transformed to the quantile scale, we initially considered dose response (DR) models \cite{Slob2002, Wilson2014}. Because the DR model implementations did not easily accommodate covariates or the replicate observations and also fit relatively complex models ($\le$ 5 parameters), we instead modeled the data with a zero-one-inflated beta (ZOIB) distribution with the following parameterization:
\begin{equation}
	p(y_{i}) = \begin{cases} 
      			\alpha(1 - \gamma) & y_{i} = 0 \\
      			\alpha \gamma & y_{i} = 1 \\
     			 \frac{y_{i}^{\mu\phi - 1}(1 - y_{i})^{(1 - \mu)\phi - 1}}{B(\mu \phi, (1 - \mu)\phi)} & y_{i} \not\in \{0, 1\}
   		\end{cases}
\end{equation}
$\alpha$ is the zero-one-inflation probability (probability that a zero or one occurs), $\gamma$ is the conditional one-inflation probability (probability that one occurs rather than zerio), $B(.)$ is the beta function \cite{Casella2002}, and $\phi$ is a positive precision parameter. For the link function, we used the logit: $g(\eta)= \log\large(\frac{\eta}{1 - \eta}\large)$. Zero-one-inflation was necessary because standard beta regression expects $y \in (0, 1)$, meaning it cannot handle values at the boundaries.

The H3K36me3 data scaled to the proportion of the maximum H3K36me3 measured within a replicate (three replicates per gene per condition) results in three values of 1 for each gene and condition pairing. Additionally, zeros may be observed. We used this scale of the data to better standardize ChIP-seq dynamics across cells and better detect consistent patterns compared to the normalized ChIP-seq data. However, it does represent a challenging formulation in the context of a GLMM, and possibly even an abuse of the underlying assumptions of a beta regression model, specifically. The zeros and ones are informative, but would strongly violate the expectations of standard beta regression, resulting in anti-conservative, extreme parameter estimates. To avoid this issue, ZOIB conservatively drops out zeros and ones in terms of parameter estimation, resulting in less extreme estimates for the time effect. Alternatively, we modeled the non-quantile, normalized ChIP-seq data (quasi-counts).

\section*{Zero-inflated negative binomial regression model of H3K36me3 quasi-counts}
The normalized ChIP-seq data after being processed and normalized, ranged from 0 to 1.374346. The distribution was consistent in shape with common count distributions, \eg Poisson and negative binomial, exemplified by being non-negative with a right skew. We calculated quasi-counts as $y_{i}^{\text{quasi}} = \text{round}(y_{i} \times 1000)$. Though this transformation is artificial, it produces a new distribution that is proportional to the original and consistent with count distributions.

For the quasi-count scale, we modeled the data with a zero-inflated negative binomial (ZINB) with the following parameterization:
\begin{equation}
	p(y_{i}) = \begin{cases} 
			{{y_{i} + \phi - 1}\choose y_{i}} \large(\frac{\mu}{\mu + \phi}\large)^{y_{i}}\large(\frac{\phi}{\mu + \phi}\large)^{\phi} & y_{i} > 0 \\
      			\xi + (1 - \xi)\text{NB}(y_{i} = 0) & y_{i} = 0
   			\end{cases}
\end{equation}
$\xi$ is the zero-inflation probability, $\text{NB}(.)$ is the non-zero-inflated negative binomial probability mass function, and $\phi$ is a positive precision parameter. As $\phi \rightarrow \infty$, the negative binomial distribution converges to the Poisson distribution. The ZINB distribution estimates the zero observations as a mixture of true zeros, expected by the NB distribution, with an additional component from drop-outs, resulting in the zeros having less influence on the parameter estimates.

The inference on the H3K36me3 time rate dynamics based on either ZOIB and ZINB should be consistent with each other. The quantile data scale is more standardized across genes and conditions, but also overly conservative when modeled by ZOIB regression, due to essentially removing the effect of zeros and ones on parameter inference. By contrast, the quasi-count scale is more artificial and disparate across genes and conditions, but more closely represented the raw data. It also makes more complete use of the data--by not excluding the maximum values which was transformed to one in the quantile data--for parameter estimation.

\section*{Time models}

\subsection*{Continuous}

We modeled the gain or loss of H3K36me3 with a continuous time variable in the linear predictor of the model, 
\begin{equation}
	\eta_{ij} = \mu + u_{i} + (\beta_{\text{time}} + v_{i})x_{ij},
\end{equation}
where $\mu$ is a shared intercept term, $x_{ij}$ is the $j$\textsuperscript{th} timepoint (in minutes) for the $i$\textsuperscript{th} sample, and $\beta_{\text{time}}$ is the change rate with time. $u_{i}$ and $v_{i}$ are random, or group-level \cite{Gelman2006}, effects that account for the longitudinal nature of the data, and modeled with the following priors: $\text{N}(0, \tau^{2}_{u})$ and $\text{N}(0, \tau^{2}_{v})$, respectively. For all genes and conditions, we recorded the posterior mean ($\widehat{\beta}_{\text{time}, kl}$) as a point estimate for the change in H3K36me3 (proportion or quasi-count) with time for gene $k$ and condition $l$, the standard error on the estimate, and the 95\% Credible Interval (CrI), which we used to define ``confident'' genes (CrI that do not cover 0) for a given condition. $\widehat{\beta}_{\text{time}, kl}$ were plotted and correlated with additional covariates of interests in order to identify potential relationships with other factors of interest.

\subsubsection*{Testing for non-zero effect of condition with time}

To formally test for a non-zero effect of condition with time is infeasible because it would require the joint estimation across all genes and conditions in a Bayesian context. Further, GLMMs are challenging models to fit, and not amenable to reliable likelihood-based inference, given the number of genes observed here. As an alternative, we fit a second model from the posterior mean $\widehat{\beta}_{\text{time}, kl}$, estimated for gene $k$ and condition $l$, described above. These parameters were modeled as normally distributed, which can be viewed as a latent variable that we model in a second regression as:
\begin{equation}
	\beta_{\text{time}, kl} = u_{k} + \delta_{\text{WA}}I\{l = \text{WA}\} + \delta_{\text{WL}}I\{l = \text{WL}\} + \delta_{\text{WEL}}I\{l = \text{WEL}\} + \varepsilon_{kl},
	\label{eq:alt_model}
\end{equation}
where $u_{k}$ is a gene-specific random effect, modeled as $\text{N}(0, \tau^{2}_{u})$, $\delta_{\text{WA}}$, $\delta_{\text{WL}}$, and $\delta_{\text{WEL}}$ are the condition-specific effects on the previously measured continuous time effect, modeled as fixed effects, and $\varepsilon_{kl}$ is a noise term, distributed according to $\text{N}(0, \frac{\sigma^{2}}{w_{ij}})$ with $\sigma^{2}$ representing the noise variance and $w_{kl}$ is a weight specific to gene $k$ and condition $l$. For the weight, we used $1/\text{SE}(\beta_{\text{time}, kl})$ from the GLMM model, effectively down weighting the influence of effect estimates with large standard error. $I\{A\}$ represents the indicator function, returning 1 if the conditional statement A is satisfied and 0 if not. 

Given that the effects can be modeled with a normal distribution, representing a linear mixed effect model (LMM) with weights, we used the R package lme4 \cite{Bates2015}. Through ANOVA \cite{Venables2010} with maximum likelihood estimates, we compared the model in Equation \ref{eq:alt_model} to a null model with an intercept and no condition fixed effects, resulting in an ANOVA $p$-value $<$ \num{2.2e-16}. Using the R package emmeans \cite{emmeans}, we performed Tukey \textit{post hoc} tests of pairwise differences \cite{Venables2010} between the conditions, which were all found to be significant (Tukey $p$-values $<$ 0.0001). Notably, the rate of H3K36me3 loss was greater for WEL compared to WL.

\subsection*{Categorical}

WL and WEL had similar H3K36me3 dynamics with time. To more directly compare their dynamics, we simultaneously analyzed WL and WEL data per gene within a categorical time model, allowing for greater flexibility and non-linearity with respect to time:
\begin{align}
	\eta_{ijl} = &\underbrace{\mu + u_{i}}_{\text{WL time0}} + \underbrace{(\omega_{\text{WEL}} + w_{i})I\{l = \text{WEL}\}}_{\text{WEL time0}} \\ 
	&+ \underbrace{\sum_{p = 1}^{3}(\beta_{\text{timepoint}}^{p} + v_{i}^{p})I\{j = p\}}_{\text{WL timepoint }p} \nonumber \\ 
	&+ \underbrace{\sum_{p = 1}^{3}(\delta_{\text{timepoint}}^{p} + z_{i}^{p})I\{j = p, l = \text{WEL}\}}_{\text{WEL timepoint }p},\nonumber
\end{align}
where $\mu$ is the intercept representing, representing WL at time0, $\omega_{\text{WL}}$ is the deviation of WEL from WL, $\beta_{\text{timepoint}}^{p}$ is the effect comparing timepoint $p$ to $0$ for WL, and $\delta_{\text{timepoint}}^{q}$ represents effect for timepoint $p$ for WEL compared to WL. $u_{i}$, $w_{i}$, $v_{i}^{p}$, $z_{i}^{p}$ are group-level effects that model the correlations within replicates, and have the following prior distributions: $\text{N}(0, \tau^{2}_{u})$, $\text{N}(0, \tau^{2}_{w})$, $\text{N}(0, \tau^{2}_{v,p})$, and $\text{N}(0, \tau^{2}_{z,p})$, respectively. 
%$I\{A\}$ represents the indicator function, returning 1 if condition A is satisfied and 0 if not.
Similar to the continuous time model, we recorded posterior means and 95\% CrI for $\delta_{\text{timepoint}}^{p}$. We fit the categorial time model with the quantile data and ZOIB, though it could be used with the quasi-counts and ZINB as well.

\subsection*{Interpreting estimated effects}

The interpretation of the regression coefficients will depend on whether ZOIB or ZINB was used. For ZOIB, effects represent log odds ratio (OR) for change in proportion H3K36me3 (relative to the sample maximum) per minute. For ZOIB, the effects are log change in quasi-counts per minute. We emphasize that these data were highly derived, resulting in some reduction in the interpretability or tangibility of their estimates. Regardless of data scale, positive effects represent increasing levels of trimethyl marks and negative effects represent decreasing marks. We view large scale trends across genes and/or conditions as meaningful.

\section*{Model specification, sampling, and convergence}

A Bayesian model requires the specification of prior distributions for the various parameters. We used the default settings from brms. Briefly, for fixed, or population-level, effects, an improper flat prior over the reals was used. Group-level effects are modeled as normal variables with standard deviation parameter. These are modeled with half Student-$t$ distributions with 3 degrees of freedom and a minimal scale parameter of 10 \cite{Gelman2006}, which brms potentially increases based on the data to insure that the prior is minimally informative. The LKJ-correlation prior is used to model the correlations between the group-level effects on the same grouping factor \cite{Lewandowski2009}.

Bayesian inferences involves random sampling from the joint posterior of the model parameters. For each Stan model, we ran four Monte Carlo Markov Chains (MCMC), each with 2,000 iterations of warm-up and sampling. Initial values for parameters for each chain were randomly generated within Stan. The the adaptive delta parameter, necessary for the No-U-turn Sampler \cite{Hoffman2014} used by Stan, was set to 0.8, the default used by brms.

There are various diagnostics for the MCMC samples that can be used to determining whether the model is converging and performing well. We used the split-$\widehat{R}$ statistic \cite{Gelman2013}, a ratio of the average variance within chains to the variance with the pooled chains. A split-$\widehat{R}$ value close to 1 means the variances within each chain are similar, and thus the model is likely mixing well and converging. Guidelines from the Stan development team state that models with split-$\widehat{R} > 1.1$ have not converged and should not be used for inference. To ensure replicable results and declare convergence and ensure reproducible results, we set the seed and ran all models in Stan (through brms) for a given gene. We then checked that split-$\widehat{R} < 1.1$ for all parameters. If this was satisfied, we declared convergence and recorded the seed as well as posterior means and CrIs for the parameters. If any split-$\widehat{R} > 1.1$, convergence failed, and we set a new seed and repeated the process. We capped that number of repeats at 10. If convergence is not met after 10 iterations, we declare modeling to have failed for those genes, likely due to oddly distributed and noisy data.

\bibliographystyle{unsrt}
\bibliography{stat_methods_GK}

\end{document}